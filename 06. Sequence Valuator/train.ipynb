{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from math import pi\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset, DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выбранный файл: /home/vest/Desktop/Work/NeuralNetworks/ecg-anomaly-detection/.workspace/Resources/SecondDone/ECGr1.C.S.V.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>edge</th>\n",
       "      <th>time</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.190297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.177645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.194514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.160777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608595</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608595.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608596</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608596.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608597</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608597.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608598</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608598.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608599</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608599.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           value  edge      time  group\n",
       "0       0.190297   0.0       0.0    NaN\n",
       "1       0.164994   0.0       1.0    NaN\n",
       "2       0.177645   0.0       2.0    NaN\n",
       "3       0.194514   0.0       3.0    NaN\n",
       "4       0.160777   0.0       4.0    NaN\n",
       "...          ...   ...       ...    ...\n",
       "608595  0.000000   0.0  608595.0    NaN\n",
       "608596  0.000000   0.0  608596.0    NaN\n",
       "608597  0.000000   0.0  608597.0    NaN\n",
       "608598  0.000000   0.0  608598.0    NaN\n",
       "608599  0.000000   0.0  608599.0    NaN\n",
       "\n",
       "[608600 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# #! Сначала склеить разметку, а потом уже определить разрывы и разметить цифрой 2 начала предупреждающих участков\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "filePath = filedialog.askopenfilename(filetypes=[(\"Parquet Files\", \"*.parquet\")])\n",
    "if filePath:\n",
    "    print(\"Выбранный файл:\", filePath)\n",
    "    fileName, fileExtension = os.path.splitext(filePath)\n",
    "    if fileExtension == '.parquet':\n",
    "        dfOriginal = pd.read_parquet(filePath)\n",
    "        df = dfOriginal.copy()\n",
    "    else:\n",
    "        print(\"Выбран неверный файл\")\n",
    "        exit()\n",
    "else:\n",
    "    print(\"Выбор файла отменен.\")\n",
    "    exit()\n",
    "\n",
    "df['value'] = (df['value'] - df['value'].min()) / (df['value'].max() - df['value'].min())       # Нормализация данных\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SecondEcgDataset(Dataset):\n",
    "#     def __init__(self, df):\n",
    "#         self.df = df\n",
    "#         self.segmentStarts = df.index[df['edge'] > 0].tolist()\n",
    "#         self.startsCount = len(self.segmentStarts)\n",
    "\n",
    "#         self.cachedTensors = []\n",
    "#         self._get_segment_tensor()\n",
    "#         self.segmentsCount = len(self.cachedTensors)\n",
    "    \n",
    "#     def _get_segment_tensor(self):\n",
    "#         for index in range(self.startsCount):\n",
    "#             result = 0\n",
    "#             if index + 1 < len(self.segmentStarts):\n",
    "#                 if self.df.at[self.segmentStarts[index], 'edge'] < 2:\n",
    "#                     segment = self.df.iloc[self.segmentStarts[index]:self.segmentStarts[index+1]]\n",
    "#                     result = 1\n",
    "#             elif self.df.at[self.segmentStarts[index], 'edge'] < 2:\n",
    "#                 segment = self.df.iloc[self.segmentStarts[index]:]\n",
    "#                 result = 1\n",
    "\n",
    "#             if result:\n",
    "#                 segmentValues = segment['value']\n",
    "#                 segmentTensor = torch.tensor(segmentValues.to_numpy(), dtype=torch.float).unsqueeze(1)\n",
    "#                 padding = 200 - len(segmentTensor)\n",
    "#                 if padding > 0:\n",
    "#                     segmentTensor = torch.cat((segmentTensor, torch.zeros(padding, 1)), dim=0)\n",
    "#                 elif padding < 0:\n",
    "#                     print('В данные зашёл сегмент неверной длины')\n",
    "#                 self.cachedTensors.append(segmentTensor)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.segmentsCount\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         segmentTensor = self.cachedTensors[index]\n",
    "#         return segmentTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecondEcgDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.segmentStarts = df.index[df['edge'] > 0].tolist()\n",
    "        self.startsCount = len(self.segmentStarts)\n",
    "\n",
    "        self.cachedTensors = []\n",
    "        self.cachedLabels = []\n",
    "        self._get_segment_tensor()\n",
    "        self.segmentsCount = len(self.cachedTensors)\n",
    "    \n",
    "    def _get_segment_tensor(self):\n",
    "        for index in range(self.startsCount):\n",
    "            result = 0\n",
    "            if index + 1 < len(self.segmentStarts):\n",
    "                if self.df.at[self.segmentStarts[index], 'edge'] != 2:      # По сути условие, что длина отрезка меньше 200\n",
    "                    segment = self.df.iloc[self.segmentStarts[index]:self.segmentStarts[index+1]]\n",
    "                    result = 1\n",
    "            elif self.df.at[self.segmentStarts[index], 'edge'] != 2:        #! Возможно это нужно будет убрать, т.к. тут в выборку может попасть отрезок длиной больше 200\n",
    "                segment = self.df.iloc[self.segmentStarts[index]:]\n",
    "                result = 1\n",
    "\n",
    "            if result:\n",
    "                segmentValues = segment['value']\n",
    "                labelValue = (1 if segment.iloc[0]['edge'] == 3 else 0)\n",
    "                segmentTensor = torch.tensor(segmentValues.to_numpy(), dtype=torch.float).unsqueeze(1)\n",
    "                # print(segmentTensor.shape)\n",
    "                labelTensor = torch.tensor(labelValue, dtype=torch.float).unsqueeze(0)\n",
    "                # print(labelTensor.shape)\n",
    "                padding = 200 - len(segmentTensor)\n",
    "                if padding > 0:\n",
    "                    segmentTensor = torch.cat((segmentTensor, torch.zeros(padding, 1)), dim=0)\n",
    "                elif padding < 0:\n",
    "                    print('В данные зашёл сегмент неверной длины')\n",
    "                    exit()\n",
    "                self.cachedTensors.append(segmentTensor)\n",
    "                self.cachedLabels.append(labelTensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.segmentsCount\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #segmentTensor = self.cachedTensors[index]\n",
    "        #return segmentTensor\n",
    "        return self.cachedTensors[index], self.cachedLabels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5505\n",
      "3853\n",
      "1652\n"
     ]
    }
   ],
   "source": [
    "dataset = SecondEcgDataset(df)\n",
    "print(len(dataset))\n",
    "#! Подумать, как размешать датасет перед разделением\n",
    "trainDataset, valDataset = random_split(dataset, [int(0.7 * len(dataset)), len(dataset) - int(0.7 * len(dataset))])\n",
    "# trainDataset, valDataset, testDataset = random_split(dataset, [int(0.6 * len(dataset)), int(0.2 * len(dataset)), len(dataset) - int(0.6 * len(dataset)) - int(0.2 * len(dataset))])\n",
    "print(len(trainDataset))\n",
    "print(len(valDataset))\n",
    "\n",
    "trainDataloader = torch.utils.data.DataLoader(trainDataset, batch_size=10, shuffle=True)\n",
    "valDataloader = torch.utils.data.DataLoader(valDataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMAutoencoder(nn.Module):\n",
    "#     def __init__(self, input_size=1, hidden_size=64, num_layers=1, bidirectional=True):\n",
    "#         super(LSTMAutoencoder, self).__init__()\n",
    "\n",
    "#         # Encoder\n",
    "#         self.encoder = nn.LSTM(\n",
    "#             input_size=input_size,\n",
    "#             hidden_size=hidden_size,\n",
    "#             num_layers=num_layers,\n",
    "#             batch_first=True,\n",
    "#             bidirectional=bidirectional\n",
    "#         )\n",
    "\n",
    "#         # Decoder\n",
    "#         self.decoder = nn.LSTM(\n",
    "#             input_size=(2 * hidden_size if bidirectional else hidden_size),\n",
    "#             hidden_size=input_size,\n",
    "#             num_layers=num_layers,\n",
    "#             batch_first=True,\n",
    "#             bidirectional=bidirectional\n",
    "#         )\n",
    "\n",
    "#         self.resulter = nn.Linear(2 * input_size if bidirectional else input_size, 1)\n",
    "\n",
    "#         # Sigmoid\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Encoder\n",
    "#         output, _ = self.encoder(x)\n",
    "\n",
    "#         # Decoder\n",
    "#         output, _ = self.decoder(output)\n",
    "\n",
    "#         # Resulter\n",
    "#         output = self.resulter(output)\n",
    "\n",
    "#         # Sigmoid\n",
    "#         output = self.sigmoid(output) \n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMAutoencoder(nn.Module):\n",
    "#     def __init__(self, input_size=1, hidden_size=64, num_layers=1, bidirectional=True):\n",
    "#         super(LSTMAutoencoder, self).__init__()\n",
    "\n",
    "#         # Encoder\n",
    "#         self.encoder1 = nn.LSTM(\n",
    "#             input_size=input_size,\n",
    "#             hidden_size=hidden_size,\n",
    "#             num_layers=num_layers,\n",
    "#             batch_first=True,\n",
    "#             bidirectional=bidirectional\n",
    "#         )\n",
    "\n",
    "#         self.encoder2 = nn.LSTM(\n",
    "#             input_size=(2*hidden_size if bidirectional else hidden_size),\n",
    "#             hidden_size=hidden_size//2,\n",
    "#             num_layers=num_layers,\n",
    "#             batch_first=True,\n",
    "#             bidirectional=bidirectional\n",
    "#         )\n",
    "\n",
    "#         self.encoder3 = nn.LSTM(\n",
    "#             input_size=(hidden_size if bidirectional else hidden_size//2),\n",
    "#             hidden_size=hidden_size//4,\n",
    "#             num_layers=num_layers,\n",
    "#             batch_first=True,\n",
    "#             bidirectional=bidirectional\n",
    "#         )\n",
    "\n",
    "#         # Decoder\n",
    "#         self.decoder1 = nn.LSTM(\n",
    "#             input_size=(hidden_size//2 if bidirectional else hidden_size//4),\n",
    "#             hidden_size=hidden_size//2,\n",
    "#             num_layers=num_layers,\n",
    "#             batch_first=True,\n",
    "#             bidirectional=bidirectional\n",
    "#         )\n",
    "\n",
    "#         self.decoder2 = nn.LSTM(\n",
    "#             input_size=(hidden_size if bidirectional else hidden_size//2),\n",
    "#             hidden_size=hidden_size,\n",
    "#             num_layers=num_layers,\n",
    "#             batch_first=True,\n",
    "#             bidirectional=bidirectional\n",
    "#         )\n",
    "\n",
    "#         self.resulter = nn.Linear(2 * hidden_size if bidirectional else hidden_size, 1)\n",
    "\n",
    "#         # Sigmoid\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Encoder\n",
    "#         output, _ = self.encoder1(x)\n",
    "#         output, _ = self.encoder2(output)\n",
    "#         output, _ = self.encoder3(output)\n",
    "\n",
    "#         # Decoder\n",
    "#         output, _ = self.decoder1(output)\n",
    "#         output, _ = self.decoder2(output)\n",
    "\n",
    "#         # Resulter\n",
    "#         output = self.resulter(output)\n",
    "\n",
    "#         # Sigmoid\n",
    "#         output = self.sigmoid(output) \n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=1, seq_len=200, bidirectional=True):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        add_size = 2*hidden_size if bidirectional else hidden_size\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            input_size=add_size,\n",
    "            hidden_size=hidden_size//2,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "        self.lstm3 = nn.LSTM(\n",
    "            input_size=add_size//2,\n",
    "            hidden_size=hidden_size//4,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "\n",
    "        #self.resulter = nn.Linear(hidden_size//2 if bidirectional else hidden_size//4, 1)\n",
    "        self.resulter = nn.Linear(seq_len * add_size//4, 1)\n",
    "\n",
    "        # Sigmoid\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0 = torch.zeros(self.num_layers * 2 if self.bidirectional else self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # c0 = torch.zeros(self.num_layers * 2 if self.bidirectional else self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        #! Узнать точно, зачем это надо и насколько полезно\n",
    "\n",
    "        # Encoder\n",
    "        output, _ = self.lstm1(x)       #Output shape: [1, 200, 128]   [batch_size, seq_len, num_directions * hidden_size]\n",
    "        output, _ = self.lstm2(output)\n",
    "        # _, (hidden, _) = self.lstm3(output)#, (h0, c0))\n",
    "        output, _ = self.lstm3(output)\n",
    "        # print(torch.cat([hidden[-2], hidden[-1]], dim=1).shape)\n",
    "\n",
    "        # Resulter\n",
    "        # output = self.resulter(torch.cat([hidden[-2], hidden[-1]], dim=1))      #! Надо попробовать использовать не Hidden, а Output\n",
    "        batch_size, seq_len, _ = output.size()\n",
    "        output = output.reshape(batch_size, -1)\n",
    "        output = self.resulter(output)      #! Надо попробовать использовать не Hidden, а Output\n",
    "        # Надо, чтобы он принимал 32*200 значений\n",
    "        # print(output.shape)\n",
    "\n",
    "        # Sigmoid\n",
    "        output = self.sigmoid(output) \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMAutoencoder(\n",
      "  (lstm1): LSTM(1, 64, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(128, 32, batch_first=True, bidirectional=True)\n",
      "  (lstm3): LSTM(64, 16, batch_first=True, bidirectional=True)\n",
      "  (resulter): Linear(in_features=6400, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Параметры для создания модели\n",
    "input_size = 1 # Так как ЭКГ - одномерный сигнал\n",
    "hidden_size = 64 # Можно изменить в зависимости от сложности задачи и размера данных\n",
    "num_layers = 1 # Можно изменить в зависимости от сложности задачи\n",
    "\n",
    "# Создание экземпляра модели\n",
    "device = (\"cuda\")\n",
    "# model = LSTMAutoencoder(input_size, hidden_size, num_layers).to(device)\n",
    "model = LSTMAutoencoder().to(device)\n",
    "print(model)\n",
    "# Определение функции потерь и оптимизатора\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "def train(trainDataloader, valDataloader, model, criterion, optimizer):\n",
    "    # Обучение модели\n",
    "    model.train()\n",
    "    trainPbar = tqdm(trainDataloader, desc=\"Training\")\n",
    "    for inputs, targets in trainPbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        trainPbar.set_postfix({'Loss': f'{loss.item()}'})\n",
    "\n",
    "    # Валидация модели\n",
    "    model.eval() # Переводим модель в режим валидации\n",
    "    valPbar = tqdm(valDataloader, desc=\"Validating\")\n",
    "    with torch.no_grad(): # Отключаем вычисление градиентов\n",
    "        for inputs, targets in valPbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            valLoss = criterion(outputs, targets)\n",
    "            valPbar.set_postfix({'Val_Loss': f'{valLoss.item()}'})\n",
    "    \n",
    "    trainPbar.close()\n",
    "    valPbar.close()\n",
    "\n",
    "    return loss.item(), valLoss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 234.01it/s, Loss=0.0335957333445549]  \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 666.37it/s, Val_Loss=0.03349548205733299] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 242.72it/s, Loss=0.03331838548183441] \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 661.25it/s, Val_Loss=0.03349553793668747] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 236.58it/s, Loss=0.033387936651706696]\n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 650.56it/s, Val_Loss=0.03349561244249344] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 243.26it/s, Loss=0.03328767046332359] \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 657.17it/s, Val_Loss=0.033495791256427765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 238.59it/s, Loss=0.03353662043809891] \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 635.64it/s, Val_Loss=0.03349601477384567] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 241.23it/s, Loss=1.1586010456085205]  \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 620.91it/s, Val_Loss=0.03349611908197403] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 231.98it/s, Loss=0.03350343555212021] \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 596.89it/s, Val_Loss=0.03349648416042328] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 239.50it/s, Loss=0.03358229249715805] \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 603.58it/s, Val_Loss=0.033496610820293427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 233.02it/s, Loss=0.03351720795035362] \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 622.64it/s, Val_Loss=0.03349679708480835] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 238.90it/s, Loss=0.03322135657072067] \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 639.80it/s, Val_Loss=0.033496905118227005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 223.80it/s, Loss=0.03358478844165802] \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 609.65it/s, Val_Loss=0.03349709510803223] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 234.36it/s, Loss=1.1529401540756226]  \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 609.08it/s, Val_Loss=0.03349713236093521] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 386/386 [00:01<00:00, 226.40it/s, Loss=1.1529852151870728]  \n",
      "Validating: 100%|██████████| 166/166 [00:00<00:00, 531.23it/s, Val_Loss=0.03349731117486954] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 251/386 [00:01<00:00, 234.93it/s, Loss=0.033603351563215256]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     ll, vl \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainDataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalDataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainDataloader, valDataloader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m trainPbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/Desktop/Work/NeuralNetworks/ecg-anomaly-detection/.workspace/.netVenv/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/NeuralNetworks/ecg-anomaly-detection/.workspace/.netVenv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000000001)\n",
    "\n",
    "ll, vl = 0, 0\n",
    "for epoch in range(1000):\n",
    "    print(f'Epoch: {epoch} ')\n",
    "    ll, vl = train(trainDataloader, valDataloader, model, criterion, optimizer)\n",
    "\n",
    "print('---------------------------------------------------------------------------------------------')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.02609984390437603\n",
      "ValLoss:  0.026220696046948433\n"
     ]
    }
   ],
   "source": [
    "print('Loss: ', ll)\n",
    "print('ValLoss: ', vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "torch.save(model.state_dict(), '../.workspace/Models/SecondStageModel.25.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
